{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEB SCRAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bing_image_downloader import downloader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Define search terms and parameters\n",
    "search_terms = [\"bank statement\", \"profit and loss statement\", \"balance sheet\", \"payslip\"]\n",
    "output_dir = r\"E:\\OCR BANK STATMENTS PROJECT\\VS CODE INFOSYS\\OCR BANK STATMENTS\\extracted images\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download images for each search term\n",
    "for term in search_terms:\n",
    "    downloader.download(term, limit=50, # Set number of images per term\n",
    "                        output_dir=output_dir,\n",
    "                        adult_filter_off=True, \n",
    "                        force_replace=False,\n",
    "                        timeout=60)\n",
    "\n",
    "    # Path for images of the current term\n",
    "    term_dir = os.path.join(output_dir, term)\n",
    "    \n",
    "    # Gather all image paths in a list\n",
    "    image_paths = [os.path.join(term_dir, img) for img in os.listdir(term_dir) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
    "    \n",
    "    # Convert images to PDF\n",
    "    if image_paths:  # Ensure there are images to process\n",
    "        images = [Image.open(img_path).convert('RGB') for img_path in image_paths]\n",
    "        \n",
    "        # Save images as PDF\n",
    "        pdf_path = os.path.join(output_dir, f\"{term.replace(' ', '_')}.pdf\")\n",
    "        images[0].save(pdf_path, save_all=True, append_images=images[1:])\n",
    "        \n",
    "print(\"Images downloaded and saved as PDFs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FETCH IMAGES FROM DATA BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudinary\n",
    "import cloudinary.api\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Configure Cloudinary with your credentials\n",
    "cloudinary.config(\n",
    "    cloud_name='dopwnz1ze',\n",
    "    api_key='172931444248964',\n",
    "    api_secret='x6UFGqc1cSfBWcrTAGy7odv8duA'\n",
    ")\n",
    "\n",
    "# List of Cloudinary folders to retrieve images from\n",
    "cloudinary_folders = [\"BALANCE SHEET\",\"PROFIT AND LOSS\", \"BANK STATMENTS\", \"PAYSLIP\"]  # Add your folder names here\n",
    "output_base_dir = r\"E:\\OCR BANK STATMENTS PROJECT\\VS CODE INFOSYS\\OCR BANK STATMENTS\\extracted images\"  # Base directory to save images\n",
    "\n",
    "# Create the base output directory if it doesn't exist\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "# Retrieve images from each Cloudinary folder\n",
    "for folder in cloudinary_folders:\n",
    "    print(f\"Retrieving images from Cloudinary folder: {folder}\")\n",
    "    \n",
    "    # Create a unique subdirectory for each Cloudinary folder\n",
    "    folder_output_dir = os.path.join(output_base_dir, folder.replace('/', '_'))\n",
    "    os.makedirs(folder_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Pagination handling for large folders\n",
    "    next_cursor = None\n",
    "    while True:\n",
    "        try:\n",
    "            # Fetch images from Cloudinary folder (up to 100 per request)\n",
    "            response = cloudinary.api.resources(type=\"upload\", prefix=folder, max_results=100, next_cursor=next_cursor)\n",
    "            images = response.get('resources', [])\n",
    "            next_cursor = response.get('next_cursor')  # For paginated results\n",
    "            \n",
    "            # Process each image\n",
    "            for image in images:\n",
    "                image_url = image['secure_url']\n",
    "                image_public_id = image['public_id']\n",
    "                print(f\"Image URL: {image_url}\")\n",
    "                \n",
    "                # Download and save each image to its folder-specific subdirectory\n",
    "                img_data = requests.get(image_url).content\n",
    "                img_filename = os.path.join(folder_output_dir, f\"{image_public_id.replace('/', '_')}.jpg\")\n",
    "                with open(img_filename, 'wb') as handler:\n",
    "                    handler.write(img_data)\n",
    "                    print(f\"Downloaded {img_filename}\")\n",
    "            \n",
    "            # Break the loop if there are no more pages\n",
    "            if not next_cursor:\n",
    "                break\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving images from Cloudinary folder '{folder}': {e}\")\n",
    "            break\n",
    "\n",
    "print(\"Image retrieval and download completed for all folders.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
